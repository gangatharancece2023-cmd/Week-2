the primary focus was on systematically organizing and preparing the fabric microstructure dataset for deep learning–based classification. The dataset consists of microscope images taken at 60x magnification, representing 14 different fabric classes. Each class folder contains multiple image samples, and ensuring a consistent structure was important for smooth processing during model training. The dataset was reviewed to remove any corrupted, extremely blurred, or low-quality images that could negatively affect model performance. Following this, a preprocessing pipeline was implemented to standardize the images. This included resizing all images to a uniform resolution and applying center cropping to ensure that the textures remained the main region of interest. Additionally, normalization was applied to bring all pixel values into a consistent scale suitable for neural network training.  To improve the model’s robustness and ability to generalize, data augmentation strategies were incorporated. These involved random rotations, flips, and brightness adjustments to simulate realistic variations in microscope imaging conditions. After the dataset preparation, the model training pipeline was set up using the EfficientNet-B0 architecture. This model was chosen because of its strong balance between computational efficiency and accuracy in texture recognition tasks. Transfer learning was applied, meaning the model was initialized with pretrained weights and then fine-tuned using the fabric dataset. The training process was tested successfully, establishing a baseline accuracy and confirming that the data and framework were functioning correctly. Overall, Week 2 laid the foundational steps for reliable and scalable model development moving forward.
